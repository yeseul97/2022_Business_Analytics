## âœ 5ë²ˆì§¸ íŠœí† ë¦¬ì–¼ "Semi-Supervised Learning"

  âœ” ì ì€ labeled dataê°€ ìˆìœ¼ë©´ì„œ ì¶”ê°€ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” ëŒ€ìš©ëŸ‰ì˜ unlabeled dataê°€ ìˆì„ ë•Œ

  âœ” ì†ŒëŸ‰ì˜ labeled dataì—ëŠ” supervised learningì„ ì ìš©í•˜ê³  unlabeled dataì—ëŠ” unsupervised learningì„ ì ìš©í•´ ì„±ëŠ¥í–¥ìƒì„ ëª©í‘œë¡œ í•¨.

  âœ” ë°ì´í„° ìì²´ì˜ ë³¸ì§ˆì ì¸ íŠ¹ì„±ì´ ëª¨ë¸ë§ ëœë‹¤ë©´ ì†ŒëŸ‰ì˜ labeled dataë¥¼ í†µí•œ ì•½ê°„ì˜ ê°€ì´ë“œë¡œ ì¼ë°˜í™” ì„±ëŠ¥ì„ ëŒì–´ì˜¬ë¦´ ìˆìŒ. 

![image](https://user-images.githubusercontent.com/67623921/209644289-622ed290-b74a-4d6e-a6c9-e0832ca7c189.png)
ì¶œì²˜: https://blog.est.ai/2020/11/ssl/


### 1ï¸âƒ£ Proxy-label method 

  - Labeled setìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì„ ì´ìš©í•´ unlabeled data pointë“¤ì— labelì„ ë‹¬ì•„ì£¼ëŠ” ê¸°ë²•


  - ë§Œì•½ Labeled setì˜ ë¶„í¬ë¥¼ ë²—ì–´ë‚˜ëŠ” ìƒ˜í”Œë“¤ì—ëŠ” ì œëŒ€ë¡œ ëœ labelì„ ë‹¬ì•„ì£¼ê¸° ì–´ë µê¸° ë•Œë¬¸ì— ì„±ëŠ¥í–¥ìƒì— í•œê³„ê°€ ìˆë‹¤ëŠ” ë‹¨ì ì´ ìˆìŒ. 


  - ê·¸ë˜ë„ Labeled set ë¶„í¬ ë‚´ì˜ ìƒ˜í”Œë“¤ì— ëŒ€í•´ interpolationí•˜ëŠ” íš¨ê³¼ê°€ ìˆê¸°ë•Œë¬¸ì— ì•„ì§ë„ ë§ì´ ì‚¬ìš©ë˜ëŠ” ê¸°ë²•ì„. 

  #### ğŸ“Œ Method 1. Pseudo Label (13')
  ![image](https://user-images.githubusercontent.com/67623921/209645395-273502dc-389f-4c1c-a29f-5c8441e0bdf2.png)
  ì¶œì²˜: https://sanghyu.tistory.com/177


### 2ï¸âƒ£ Consistency regularization

  - ì´ ë°©ë²•ì€ unlabeled data pointì— ì‘ì€ perturbationì„ ì£¼ì–´ë„ ì˜ˆì¸¡ì˜ ê²°ê³¼ì—ëŠ” ì¼ê´€ì„±ì´ ìˆì„ ê±°ë¼ê³  ê°€ì •í•¨. 


  - unlabeled dataì— data augmentationì„ í†µí•´ classê°€ ë°”ë€Œì§€ ì•Šì„ ì •ë„ì˜ ë³€í™”ë¥¼ ì¤¬ì„ ë•Œ, ì› ë°ì´í„°ì™€ì˜ ì˜ˆì¸¡ê²°ê³¼ê°€ ê°™ì•„ì§€ë„ë¡ unsupervised lossë¥¼ ì£¼ì–´ í•™ìŠµí•˜ê²Œ ë¨. 


  - ì´ë¥¼ í†µí•´ ì•½ê°„ í—·ê°ˆë¦¬ëŠ” ìƒ˜í”Œë“¤ì— ëŒ€í•´ classë¥¼ ìœ ì—°í•˜ê²Œ ì˜ˆì¸¡í•  ìˆ˜ ìˆë„ë¡ í•´ì¤Œ. 


  - ì„±ëŠ¥ì´ ì¢‹ì€ semi-supervised learning ëª¨ë¸ë“¤ì€ ëŒ€ì²´ë¡œ consistency regularizationì„ ì‚¬ìš©í•˜ê³  ìˆìŒ. 


  #### ğŸ“Œ Method 2. PI model (16')
  ![image](https://user-images.githubusercontent.com/67623921/209645936-254931a4-4b02-4496-9ef5-089c52d4cc8a.png)
  ì¶œì²˜: https://amitness.com/2020/07/semi-supervised-learning/
  
  
  #### ğŸ“Œ Method 3. VAT(17')
  ![image](https://user-images.githubusercontent.com/67623921/209646055-166bc795-a250-416f-9357-8afd04d3824b.png)
  ì¶œì²˜: https://sh-tsang.medium.com/review-virtual-adversarial-training-vat-4b3d8b7b2e92
    
  
  #### ğŸ“Œ Method 4. Mean Teacher (17')
  ![image](https://user-images.githubusercontent.com/67623921/209646198-4661e185-e44c-4d23-af9f-8960e1eb6f13.png)
  ì¶œì²˜: https://velog.io/@injokim/%EC%99%95%EC%B4%88%EA%B8%89-Semi-supervised-learning-%EC%9E%85%EB%AC%B8


  #### ğŸ“Œ Method 5. ICT (19')
  ![image](https://user-images.githubusercontent.com/67623921/209646639-8695ddbc-e433-4a9f-9884-c1e03f1c245a.png)
  ì¶œì²˜: Verma, V., Kawaguchi, K., Lamb, A., Kannala, J., Bengio, Y., & Lopez-Paz, D. (2019). Interpolation consistency training for semi-supervised learning. arXiv preprint arXiv:1903.03825.
  
  
  
### 3ï¸âƒ£ Holistic methods

  - ì—¬ëŸ¬ semi-supervised learning ê¸°ë²•ë“¤ì„ í†µí•©í•˜ê³  Mixup data augmentatinoì„ ì ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ë” ëŒì–´ ì˜¬ë¦¼.

  #### ğŸ“Œ Method 6. MixMatch (19')
  ![image](https://user-images.githubusercontent.com/67623921/209646904-61c6481e-7192-4495-9139-a8ed37d9ae9b.png)
  ì¶œì²˜: https://rain-bow.tistory.com/entry/Semi-Supervised-Learning-SSL-%EC%86%8C%EA%B0%9C-%EB%B0%8F-%EB%8F%99%ED%96%A5


  
