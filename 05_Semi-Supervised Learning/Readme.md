## âœ 5ë²ˆì§¸ íŠœí† ë¦¬ì–¼ "Semi-Supervised Learning"
 
### <ëª©ì°¨>
#### 1. Proxy-label method : `Pseudo Label`
#### 2. Consistency regularization : `PI model`, `VAT`, `Mean Teacher`, `ICT`
#### 3. Holistic methods : `MixMatch`
#### 4. ì‹¤í—˜ ê²°ê³¼

---

### 1ï¸. Proxy-label method 

  - Labeled setìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì„ ì´ìš©í•´ unlabeled data pointë“¤ì— labelì„ ë‹¬ì•„ì£¼ëŠ” ê¸°ë²•


  - ë§Œì•½ Labeled setì˜ ë¶„í¬ë¥¼ ë²—ì–´ë‚˜ëŠ” ìƒ˜í”Œë“¤ì—ëŠ” ì œëŒ€ë¡œ ëœ labelì„ ë‹¬ì•„ì£¼ê¸° ì–´ë µê¸° ë•Œë¬¸ì— ì„±ëŠ¥í–¥ìƒì— í•œê³„ê°€ ìˆë‹¤ëŠ” ë‹¨ì ì´ ìˆìŒ. 


  - ê·¸ë˜ë„ Labeled set ë¶„í¬ ë‚´ì˜ ìƒ˜í”Œë“¤ì— ëŒ€í•´ interpolationí•˜ëŠ” íš¨ê³¼ê°€ ìˆê¸°ë•Œë¬¸ì— ì•„ì§ë„ ë§ì´ ì‚¬ìš©ë˜ëŠ” ê¸°ë²•ì„. 

  #### ğŸ“Œ Method 1. `Pseudo Label` (13')
  ![image](https://user-images.githubusercontent.com/67623921/209647081-9874fab0-5f36-43a4-91d9-a224ca76e1ef.png)
  
  ì¶œì²˜: https://sanghyu.tistory.com/177


### 2ï¸. Consistency regularization

  - ì´ ë°©ë²•ì€ unlabeled data pointì— ì‘ì€ perturbationì„ ì£¼ì–´ë„ ì˜ˆì¸¡ì˜ ê²°ê³¼ì—ëŠ” ì¼ê´€ì„±ì´ ìˆì„ ê±°ë¼ê³  ê°€ì •í•¨. 


  - unlabeled dataì— data augmentationì„ í†µí•´ classê°€ ë°”ë€Œì§€ ì•Šì„ ì •ë„ì˜ ë³€í™”ë¥¼ ì¤¬ì„ ë•Œ, ì› ë°ì´í„°ì™€ì˜ ì˜ˆì¸¡ê²°ê³¼ê°€ ê°™ì•„ì§€ë„ë¡ unsupervised lossë¥¼ ì£¼ì–´ í•™ìŠµí•˜ê²Œ ë¨. 


  - ì´ë¥¼ í†µí•´ ì•½ê°„ í—·ê°ˆë¦¬ëŠ” ìƒ˜í”Œë“¤ì— ëŒ€í•´ classë¥¼ ìœ ì—°í•˜ê²Œ ì˜ˆì¸¡í•  ìˆ˜ ìˆë„ë¡ í•´ì¤Œ. 


  - ì„±ëŠ¥ì´ ì¢‹ì€ semi-supervised learning ëª¨ë¸ë“¤ì€ ëŒ€ì²´ë¡œ consistency regularizationì„ ì‚¬ìš©í•˜ê³  ìˆìŒ. 


  #### ğŸ“Œ Method 2. `PI model` (16')
  ![image](https://user-images.githubusercontent.com/67623921/209645936-254931a4-4b02-4496-9ef5-089c52d4cc8a.png)
  
  ì¶œì²˜: https://amitness.com/2020/07/semi-supervised-learning/
  
  
  #### ğŸ“Œ Method 3. `VAT` (17')
  ![image](https://user-images.githubusercontent.com/67623921/209646055-166bc795-a250-416f-9357-8afd04d3824b.png)
  
  ì¶œì²˜: https://sh-tsang.medium.com/review-virtual-adversarial-training-vat-4b3d8b7b2e92
    
  
  #### ğŸ“Œ Method 4. `Mean Teacher` (17')
  ![image](https://user-images.githubusercontent.com/67623921/209646198-4661e185-e44c-4d23-af9f-8960e1eb6f13.png)
  
  ì¶œì²˜: https://velog.io/@injokim/%EC%99%95%EC%B4%88%EA%B8%89-Semi-supervised-learning-%EC%9E%85%EB%AC%B8


  #### ğŸ“Œ Method 5. `ICT` (19')
  ![image](https://user-images.githubusercontent.com/67623921/209646639-8695ddbc-e433-4a9f-9884-c1e03f1c245a.png)
  
  ì¶œì²˜: Verma, V., Kawaguchi, K., Lamb, A., Kannala, J., Bengio, Y., & Lopez-Paz, D. (2019). Interpolation consistency training for semi-supervised learning. arXiv preprint arXiv:1903.03825.
  
  
  
### 3ï¸. Holistic methods

  - ì—¬ëŸ¬ semi-supervised learning ê¸°ë²•ë“¤ì„ í†µí•©í•˜ê³  Mixup data augmentatinoì„ ì ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ë” ëŒì–´ ì˜¬ë¦¼.

  #### ğŸ“Œ Method 6. `MixMatch` (19')
  ![image](https://user-images.githubusercontent.com/67623921/209646904-61c6481e-7192-4495-9139-a8ed37d9ae9b.png)
  
  ì¶œì²˜: https://rain-bow.tistory.com/entry/Semi-Supervised-Learning-SSL-%EC%86%8C%EA%B0%9C-%EB%B0%8F-%EB%8F%99%ED%96%A5


  
### 4. ì‹¤í—˜ ê²°ê³¼ 
![image](https://user-images.githubusercontent.com/67623921/209648099-730d6303-d2e7-44d1-b3db-f95a1f933a5e.png)

- ëŒ€ê·œëª¨ì˜ teacher modelì˜ ì§€ì‹ì„ ê°€ë²¼ìš´ student modelì— ì „ì´ì‹œí‚¤ëŠ” Knowledge distillation(KD) ë°©ë²•ì—ì„œëŠ” KL-div ì„ ì´ìš©í•¨. 

- KL-divergence lossëŠ” penultimate layer(softmax ì´ì „)ì˜ representationì„ ê°€ëŠ˜ê²Œ(?) í•˜ëŠ” ë°˜ë©´, MSE lossëŠ” ì´ëŸ° í˜„ìƒì„ ë³´ì´ì§€ ì•ŠìŒ.

  -softmax ì´ì „ì˜ representationì„ ë‹¤ì´ë ‰íŠ¸í•˜ê²Œ ë°°ìš°ëŠ” MSE lossì— ë¹„í•´ ì ë‹¹íˆ softmax distribution ê°„ì˜ ê±°ë¦¬ë§Œ ì¤„ì—¬ë„ ë˜ëŠ” KL-Divergence lossëŠ” ë‹¤ì±„ë¡œìš´(ì¦‰, high varianceë¥¼ ê°–ëŠ”?) representationì„ ë°°ìš¸ í•„ìš”ì„±ì„ ëª»ëŠë‚€ë‹¤ê³  ë³´ë©´ ë ë“¯.
  
- íŠ¹íˆ, teacherì™€ studentê°„ì˜ capacity gapì´ í´ ê²½ìš° KL-divergence lossë¥¼ ì´ìš©í•´ í•™ìŠµí•œ ë‹¤ìŒ, MSE-lossë¥¼ ì´ìš©í•´ ì´ì–´ì„œ í•™ìŠµí•˜ëŠ”, Sequenctial distillation í•™ìŠµì„ í•˜ëŠ” ê²Œ ë” íš¨ê³¼ì ì´ì—ˆìŒ.

- ë‹¨, labelì— ë…¸ì´ì¦ˆê°€ ë§ì„ ìˆ˜ë¡ Directí•˜ê²Œ logit matchingì„ ë°°ìš°ëŠ” MSE Lossë³´ë‹¤ ì†Œê·¹ì ìœ¼ë¡œ ë°°ìš°ëŠ” (Ï„ê°€ ë‚®ì€) KL-divergence lossë¥¼ ì“°ëŠ”ê²Œ bad trainingì˜ ì•…ì˜í–¥ì„ ì¡°ê¸ˆ ì¤„ì´ê¸´ í•¨.

